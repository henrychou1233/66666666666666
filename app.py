# -*- coding: utf-8 -*-
"""
app.py â€” Optimized Gradio Inference (No Domain Adaptation Re-training)
(åªåˆå§‹åŒ–ä¸€æ¬¡æ¨¡å‹ï¼Œä¸é‡æ–°è¨“ç·´ DAï¼Œå¿½ç•¥ CLIP éŒ¯èª¤)
"""

import os
import io
import torch
import numpy as np
from PIL import Image
from torchvision import transforms
from omegaconf import OmegaConf
import gradio as gr
import cv2
import matplotlib.pyplot as plt
import time
import logging

# =====================================================
# åŸºç¤è¨­å®š
# =====================================================
logging.basicConfig(level=logging.INFO, format="%(message)s")

from main import build_model
from reconstruction import Reconstruction
from anomaly_map import heat_map
from feature_extractor import build_feature_extractor

# =====================================================
# ğŸ”§ æ¨¡å‹åˆå§‹åŒ–ï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰
# =====================================================
cfg = OmegaConf.load('config.yaml')
cfg.data.category = 'one'  # ä¿®æ”¹ç‚ºä½ çš„é¡åˆ¥
cfg.model.load_chp = 300
cfg.model.DA_chp = 1

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ===== å»ºç«‹ Unet æ¨¡å‹ =====
unet = build_model(cfg)
unet = torch.nn.DataParallel(unet)

ckpt_folder = os.path.join(cfg.model.checkpoint_dir, cfg.data.category, str(cfg.model.load_chp))
if os.path.isfile(ckpt_folder):
    ckpt_path = ckpt_folder
else:
    ckpt_path = None
    for fn in os.listdir(ckpt_folder):
        if fn.endswith(('.pth', '.pt')):
            ckpt_path = os.path.join(ckpt_folder, fn)
            break
assert ckpt_path, f"âŒ æœªæ‰¾åˆ° checkpoint æª”æ¡ˆ: {ckpt_folder}"

unet.load_state_dict(torch.load(ckpt_path, map_location=device), strict=False)
unet.to(device).eval()

recon_m = Reconstruction(unet, cfg)

# ===== Domain Adaptation (åªè¼‰å…¥ï¼Œä¸é‡å»º) =====
feat_folder = os.path.join(cfg.model.checkpoint_dir, cfg.data.category, f"feat{cfg.model.DA_chp}")
if os.path.isfile(feat_folder):
    feat_path = feat_folder
else:
    feat_path = None
    for fn in os.listdir(feat_folder):
        if fn.endswith(('.pth', '.pt')):
            feat_path = os.path.join(feat_folder, fn)
            break
assert feat_path, f"âŒ æœªæ‰¾åˆ° Domain Adaptation checkpoint: {feat_folder}"

# âœ… åªè¼‰å…¥ DA çµæ§‹èˆ‡æ¬Šé‡ï¼Œä¸é€²è¡Œè¨“ç·´
fe = build_feature_extractor(cfg)
fe = torch.nn.DataParallel(fe).to(device)
fe.load_state_dict(torch.load(feat_path, map_location=device), strict=False)
fe.eval()

print(f"[INFO] âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (U-Net + DomainAdaptation) on {device}")

# =====================================================
# ğŸ§© å‰è™•ç†å‡½æ•¸
# =====================================================
def preprocess(image, img_size, device):
    tf = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Lambda(lambda t: (t * 2) - 1),
    ])
    img = image.convert('RGB')
    return tf(img).unsqueeze(0).to(device)

# =====================================================
# ğŸ“Š ç†±åœ–åˆ†æ
# =====================================================
def analyze_heatmap(heatmap_img_pil, orig_img_pil, recon_img_pil, min_area=50.0):
    heatmap_color = np.array(heatmap_img_pil.convert('RGB'))[..., ::-1]
    orig = np.array(orig_img_pil.convert('RGB'))[..., ::-1]
    recon = np.array(recon_img_pil.convert('RGB'))[..., ::-1]
    heatmap_vis = heatmap_color.copy()

    heatmap_gray = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2GRAY)
    _, mask = cv2.threshold(heatmap_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)
    contours, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    report = []
    for idx, cnt in enumerate(contours):
        area = cv2.contourArea(cnt)
        if area < min_area:
            continue
        x, y, w, h = cv2.boundingRect(cnt)
        report.append((idx, x, y, w, h, area))
        cv2.rectangle(heatmap_vis, (x, y), (x + w, y + h), (0, 0, 255), 2)
        cv2.putText(heatmap_vis, f"({x},{y})", (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    if not report:
        analysis_txt = "æ²’æœ‰åµæ¸¬åˆ°è¶…éæœ€å°é¢ç©é–€æª»çš„ç•°å¸¸å€åŸŸã€‚"
    else:
        analysis_txt = "æœ¬æ¬¡æª¢æ¸¬å…±ç™¼ç¾ä»¥ä¸‹ç•°å¸¸å€åŸŸï¼š\n"
        for idx, x, y, w, h, area in report:
            analysis_txt += f"ãƒ»ç¬¬{idx+1}å€‹ç•°å¸¸å€åŸŸï¼Œä½ç½®({x},{y})ï¼Œå¤§å°{w}Ã—{h}ï¼Œé¢ç©{area:.1f}\n"
        analysis_txt += f"\nç¸½è¨ˆåµæ¸¬åˆ° {len(report)} å€‹ç•°å¸¸å€åŸŸã€‚"

    fig, axes = plt.subplots(1, 4, figsize=(18, 5))
    images = [orig, recon, heatmap_color, heatmap_vis]
    titles = ["Original", "Reconstruction", "Raw Heatmap", "Annotated Heatmap"]
    for ax, img, title in zip(axes, images, titles):
        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        ax.set_title(title)
        ax.axis('off')
    plt.tight_layout()

    buf = io.BytesIO()
    plt.savefig(buf, format='png')
    plt.close(fig)
    buf.seek(0)
    summary_img = Image.open(buf)
    return summary_img, analysis_txt

# =====================================================
# ğŸš€ æ¨è«–å‡½æ•¸ï¼ˆä¸é‡å»ºæ¨¡å‹ï¼‰
# =====================================================
def gradio_infer(img_pil):
    time_start = time.time()
    x = preprocess(img_pil, cfg.data.image_size, device)

    with torch.no_grad():
        x0_hat = recon_m(x, x, cfg.model.w)[-1]
        amap = heat_map(x0_hat, x, fe, cfg)

    # æ­£è¦åŒ– anomaly map
    amap_min = amap.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0]
    amap_max = amap.max(dim=2, keepdim=True)[0].max(dim=3, keepdim=True)[0]
    amap_norm = (amap - amap_min) / (amap_max - amap_min + 1e-8)
    amap_norm = amap_norm.clamp(0, 1)

    # å–å¾— anomaly score
    score = float(amap_norm.view(amap_norm.size(0), -1).mean(dim=1).item())
    threshold = 0.3
    pred_label = 'Anomalous' if score > threshold else 'Good'

    # ç”Ÿæˆç†±åœ–èˆ‡é‡å»ºåœ–
    amap_img = (amap_norm[0, 0].cpu().numpy() * 255).astype(np.uint8)
    heatmap_img = Image.fromarray(amap_img)
    recon_np = ((x0_hat.squeeze(0).cpu().clamp(-1, 1) + 1) / 2 * 255).permute(1, 2, 0).byte().numpy()
    recon_img = Image.fromarray(recon_np)

    # åˆ†æç†±åœ–
    summary_img, analysis_txt = analyze_heatmap(heatmap_img, img_pil, recon_img)
    score_str = f"{score:.6f}"
    elapsed = time.time() - time_start

    info = (
        f"Anomaly score: {score_str} | Threshold: {threshold} | Prediction: {pred_label}\n"
        f"æ¨è«–èŠ±è²»æ™‚é–“ï¼š{elapsed:.3f} ç§’"
    )
    return pred_label, score_str, heatmap_img, recon_img, summary_img, analysis_txt, info

# =====================================================
# ğŸ–¼ï¸ Gradio ä»‹é¢
# =====================================================
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ§  Real-Time Diffusion Anomaly Inspector\nè«‹ä¸Šå‚³åœ–ç‰‡ï¼Œç³»çµ±å°‡é€²è¡Œç•°å¸¸æª¢æ¸¬ä¸¦è¼¸å‡ºé‡å»ºèˆ‡ç†±åœ–åˆ†æã€‚")

    with gr.Row():
        with gr.Column():
            image_input = gr.Image(label="ä¸Šå‚³åœ–ç‰‡", type="pil")
            btn = gr.Button("é–‹å§‹åµæ¸¬")
        with gr.Column():
            pred = gr.Textbox(label="åˆ†é¡çµæœ")
            score = gr.Textbox(label="ç•°å¸¸åˆ†æ•¸")
            heatmap = gr.Image(label="Anomaly Map")
            recon = gr.Image(label="Reconstruction")

    gr.Markdown("## ğŸ” ç•°å¸¸å€åŸŸåˆ†æï¼ˆå«è¼ªå»“ã€åº§æ¨™èˆ‡é¢ç©å ±å‘Šï¼‰")
    with gr.Row():
        summary_img = gr.Image(label="ç•°å¸¸ç¸½è¦½")
        analysis_txt = gr.Textbox(label="ç•°å¸¸å€åŸŸå ±å‘Š", lines=6)
    log = gr.Textbox(label="æ¨è«–è³‡è¨Š", interactive=False)

    btn.click(fn=gradio_infer,
              inputs=[image_input],
              outputs=[pred, score, heatmap, recon, summary_img, analysis_txt, log],
              api_name="predict")

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
